news_sources:
  - name: "La Nacion"
    url: "https://www.lanacion.com.ar"
    selectors:
      # Article links inside ln-card elements (hrefs follow /section/slug-nidYYYYMMDD/ pattern)
      article_list: "article.ln-card a[href*='nid']"
      # Title is always present inside the description container
      title: ".ln-card .description-container .title"
      # Category label (only present on featured articles; absent on most cards)
      category: ".ln-card .description-container .author-section"
      # Excerpt/summary (only present on larger featured articles)
      description: ".ln-card .description-container .subhead"

  - name: "Info Quilmes"
    url: "https://www.infoquilmes.com.ar/"
    selectors:
      # Links to articles (relative URLs starting with "noticias/")
      article_list: "a[href^='noticias/']"
      # Title can be in H4, H5, H6, or div.titulo
      title: "H4 a, H5 a, H6 a, div.titulo a"
      # Category tag
      category: "span.volanta"
      # Optional excerpt/description
      description: "span.copete"

github_models:
  # GitHub Models API - uses GitHub Personal Access Token
  # Create token at: https://github.com/settings/personal-access-tokens/new?name=GitHub+Models+token&user_models=read
  api_token: "${GITHUB_MODELS_TOKEN}"
  model: "gpt-4o-mini"
  timeout: 60
  batch_size: 5 # Number of articles to analyze per LLM call (1-10, recommended: 5)

discord:
  webhook_url: "${DISCORD_WEBHOOK_URL}" # Load from environment

database:
  path: "./data/seen_articles.db"

scraping:
  check_interval: 7200 # seconds (2 hours)
  max_articles_per_run: 30
  user_agent: "Mozilla/5.0 (compatible; BeaconBot/1.0)"

filtering:
  preferences_file: "./preferences.md"
  min_relevance_score: 7 # 1-10 scale (strict threshold to reduce false positives)

logging:
  level: "INFO"
  # Logs are sent to stdout (captured by Docker/systemd)
